# LLM/VLM 실무 고민 & 엔지니어링 결정

> 실제로 LLM/VLM 시스템을 구축하거나 연구를 진행할 때 반드시 마주치는 실용적 질문들.

---

## 1. 모델 선택

### 오픈소스 vs API
```
API (GPT-4, Claude, Gemini):
  장점:
    - 즉시 사용, 인프라 불필요
    - 최신 모델 자동 업데이트
    - 안전성 필터링 내장
  단점:
    - 데이터 프라이버시 (입력이 외부로)
    - 비용 (대량 사용 시)
    - 커스터마이징 불가
    - 레이턴시 불확실

오픈소스 (LLaMA, Mistral, Qwen):
  장점:
    - 데이터 완전 통제
    - 커스터마이징 (파인튜닝, 양자화)
    - 대량 사용 시 비용 효율
    - 오프라인/엣지 배포 가능
  단점:
    - 인프라 관리 필요
    - 모델 선택/평가 직접 해야
    - 안전성 직접 책임

결정 기준:
  민감 데이터 → 오픈소스
  빠른 프로토타입 → API
  대규모 프로덕션 → 비용 계산 후 결정
  특수 도메인 → 파인튜닝 가능한 오픈소스
```

### 모델 크기 선택
```
태스크 복잡도에 따른 가이드:

간단한 분류/추출 (4 classes, NER):
  7B 모델로 충분, 파인튜닝하면 3B도 가능

일반 지시 따르기, 요약:
  7B~13B: 좋음
  70B: 더 좋지만 비용 증가

복잡한 추론, 코딩, 수학:
  70B 이상 or 추론 특화 모델 (o1, R1 스타일)

장문 컨텍스트 처리:
  모델 크기보다 컨텍스트 윈도우와 lost-in-middle 성능이 중요

비용 vs 성능 실험:
  작은 모델로 먼저 시도 → 성능 부족 시 크게
  파인튜닝 > 모델 크기 증가 (태스크 특화)
```

---

## 2. 파인튜닝 결정

### 파인튜닝이 필요한가?
```
파인튜닝 안 해도 되는 경우:
  - 프롬프트 엔지니어링으로 충분한 성능
  - 데이터가 적음 (< 수백 개)
  - 빠른 프로토타입

파인튜닝이 유리한 경우:
  - 특수 도메인 언어/형식 (의료, 법률, 코드)
  - 일관된 출력 포맷 강요
  - 대량 추론 (API 비용 절감)
  - 프라이버시 (데이터를 API에 보낼 수 없음)
  - 짧은 프롬프트로 동일 성능 (추론 비용 감소)

파인튜닝 방법 선택:
  데이터 적음 + 자원 없음: LoRA (r=8~16)
  데이터 많음 + 자원 있음: Full fine-tuning
  메모리 극단적 제한: QLoRA (4-bit base + LoRA)
```

### SFT 데이터 품질 vs 양
```
LIMA 논문의 인사이트:
  1000개 고품질 데이터 > 52K 저품질 데이터

고품질의 기준:
  - 다양성: 다양한 태스크와 도메인 커버
  - 정확성: 답변이 실제로 맞아야 함
  - 형식 일관성: 원하는 출력 형식 준수
  - 적절한 길이: 너무 길거나 짧지 않게

실무 가이드:
  100개: 특정 형식 학습 가능
  1000개: 도메인 특화 충분
  10000개: 능력 추가 (새 태스크 학습)
  100000개+: 일반 모델 수준 향상
```

---

## 3. 평가 설계

### 무엇을 어떻게 평가할 것인가
```
황금률: 실제 사용 사례를 반영하는 평가 설계

평가 체계 구성:
  1. Automated metrics:
     - 정량: ROUGE, BLEU, F1 (태스크 의존)
     - 모델 기반: LLM-as-Judge (GPT-4, Claude)
     - 도메인 특화: 코드 실행 정확도, SQL 실행 결과

  2. Human evaluation:
     - 샘플 선정: 다양한 케이스 커버
     - 평가 기준 명시: Helpful/Faithful/Safe 등
     - 평가자 간 신뢰도 측정 (Cohen's κ)

  3. Red teaming:
     - 실패 케이스 의도적 탐색
     - Adversarial prompt 테스트
```

### A/B 테스트 및 평가 함정
```
흔한 실수:
  - 벤치마크 점수 ≠ 실제 사용 성능
  - LLM Judge: 자신의 출력 선호 편향 (position bias, length bias)
  - 데이터 오염: 테스트셋이 학습 데이터에 포함

좋은 평가 설계:
  - Blind evaluation: 모델 정보 숨김
  - Bidirectional: A>B와 B>A 모두 테스트 (position 편향)
  - 충분한 샘플: 통계적 유의성 확보
  - 실제 사용자 피드백 포함 (chatbot arena 방식)

평가 도구:
  - EleutherAI lm-evaluation-harness: 표준 벤치마크
  - Promptfoo: LLM 출력 자동화 테스트
  - Ragas: RAG 시스템 평가
  - DeepEval: 커스텀 평가 프레임워크
```

---

## 4. 데이터 파이프라인

### 학습 데이터 준비 체크리스트
```
전처리:
  □ 언어 필터링 (목표 언어만)
  □ 중복 제거 (문서 수준: MinHash, 문자 수준: n-gram)
  □ 품질 필터 (ppl 기반, 규칙 기반)
  □ PII 제거 (이름, 이메일, 전화번호)
  □ 독성/혐오 콘텐츠 필터

포맷:
  □ Chat template 적용
  □ Masking: 시스템/어시스턴트 파트만 loss 계산
  □ 패킹: 짧은 시퀀스 합치기 (document attention mask)
  □ 최대 길이 처리 (truncation vs drop)

균형:
  □ 도메인 혼합 비율 설정 (수학:코드:일반 = ?)
  □ 언어 혼합 비율
  □ 난이도 분포 확인
```

### 데이터 품질 보증
```
자동 검증:
  - 형식 검증: JSON parsable, template 준수
  - 길이 분포: 너무 짧거나 긴 예시 확인
  - 언어 감지: 의도한 언어인지
  - 중복 체크: 정확히 같은 예시

사람 검증 (샘플링):
  - 랜덤 100~200개 직접 읽어보기
  - 오류 패턴 발견 → 전체 데이터에 수정 적용
  - 레이블 오류 추정 → 전체 규모 계산

지속적 모니터링:
  - 학습 중 loss 분포 (이상한 배치 탐지)
  - 특정 소스 perplexity 추적
```

---

## 5. 프로덕션 시스템 설계

### LLM 시스템 아키텍처
```
기본 구성요소:
  ┌─────────────────────────────────────┐
  │           Client Layer              │
  │    (API Gateway, Rate Limiting)     │
  └────────────────┬────────────────────┘
                   │
  ┌────────────────▼────────────────────┐
  │         Orchestration Layer         │
  │  (LangChain/LlamaIndex, Prompt Mgmt)│
  └────────────────┬────────────────────┘
                   │
  ┌────────────────▼────────────────────┐
  │          Inference Layer            │
  │    (vLLM, TensorRT-LLM, Triton)    │
  │    [Load Balancer → GPU Pool]       │
  └────────────────┬────────────────────┘
                   │
  ┌────────────────▼────────────────────┐
  │         Storage Layer               │
  │  (Vector DB, Cache, Model Registry) │
  └─────────────────────────────────────┘

주요 설계 결정:
  - 스트리밍 vs 배치
  - 캐싱 전략 (Exact match, Semantic cache)
  - 폴백 전략 (모델 실패 시)
  - 버전 관리 (모델 A/B 테스트)
```

### 성능 최적화 순서
```
병목 찾기 먼저:
  1. 프로파일링: nvidia-smi, torch.profiler
  2. 로그 분석: TTFT, TPOT, 처리량 시계열

일반적 최적화 순서 (쉬운 것부터):
  1. 배치 크기 최적화 (continuous batching)
  2. 양자화 적용 (INT8, INT4 → 2-4× 속도)
  3. Flash Attention 활성화
  4. KV Cache prefix caching
  5. Speculative decoding (draft model 준비 필요)
  6. Tensor Parallelism (GPU 추가)
  7. 커스텀 커널 (Triton)

각 최적화 전후 벤치마크:
  - tokens/sec, TTFT P99, 메모리 사용량
  - 품질 지표 (벤치마크, 샘플 검토)
```

### 장애 처리
```
예상 장애 유형:
  GPU OOM: 배치 크기 줄이기, KV cache 축소
  NCCL timeout: 네트워크 장애, GPU 오류
  모델 품질 저하: 분포 shift, 데이터 오염
  레이턴시 스파이크: GPU 경합, 네트워크 지연

장애 대응 설계:
  - Circuit breaker: 반복 실패 시 빠른 실패
  - 타임아웃 설정: 각 레이어별 적절한 timeout
  - Fallback 모델: 작은 모델로 대체
  - Graceful degradation: 일부 기능 비활성화
  - 알림 시스템: loss spike, error rate 임계값 알림

체크포인트 전략 (학습 중):
  - 빈도: 500~2000 steps (비용과 손실 균형)
  - 저장소: S3/GCS에 자동 업로드
  - 검증: 저장 후 로드 테스트
  - 보관: 최근 N개 유지 (저장소 비용)
```

---

## 6. 비용 최적화

### 학습 비용 계산
```
A100 시간 기준 (2025 기준):
  On-demand: $3-4/시간 (AWS p4d)
  Spot/Preemptible: $1-1.5/시간 (60% 절감)
  Lambda Labs: $1.5-2/시간 (A100)

LLaMA-3-8B 학습 추정:
  15T tokens, 8× A100 80GB
  tokens/sec/GPU ≈ 3000 (MFU 35%)
  전체 tokens/sec = 24000
  학습 시간 = 15×10¹² / 24000 ≈ 625000초 ≈ 174시간 ≈ 7.2일
  비용: 174 × 8 × $1.5 ≈ $2088

실제: 재시작, 디버깅 포함하면 2-3배

LLaMA-3-70B:
  64× A100 필요, ~$40000~60000 (최소 추정)
  실제 Meta 규모: 훨씬 큼
```

### 추론 비용 최적화 전략
```
1. 모델 크기 최소화:
   태스크에 필요한 최소 모델 크기 결정
   특화 파인튜닝으로 더 작은 모델 사용 가능

2. 양자화:
   INT4: 4× 메모리 감소, 1.5-2× 속도 향상
   거의 항상 적용 권장 (품질 손실 미미)

3. 캐싱:
   Exact match cache: 동일 쿼리 재사용
   Semantic cache: 유사 쿼리 (주의: 캐시 오류 가능)
   Prefix cache: 긴 system prompt 공유

4. 배치 전략:
   Continuous batching: 처리량 최대화
   Adaptive batching: 트래픽에 따른 동적 배치

5. 스케줄링:
   Spot 인스턴스: 학습/배치 추론
   Reserved: 프로덕션 실시간
   Serverless (AWS Inferentia): 간헐적 트래픽
```

---

## 7. 데이터 거버넌스와 윤리

### 학습 데이터 라이선스
```
중요한 라이선스 구분:

학습 사용 허용:
  CC0, CC-BY (출처 표기 필요)
  공개 도메인

학습 제한 가능:
  CC-BY-NC (비상업적만)
  CC-BY-SA (동일 라이선스 공유)
  일부 웹 크롤링 데이터

주의:
  책, 논문: 저작권 있음 (허락 없이 학습 시 법적 위험)
  코드: License별 다름 (MIT, Apache, GPL)
  사람 얼굴 이미지: 인격권/초상권

체크리스트:
  □ 데이터 소스별 라이선스 목록 작성
  □ 상업적 사용 가능 여부 확인
  □ 출처 표기 요구사항 확인
  □ 법무팀 검토 (대규모 시)
```

### 출력 품질과 책임
```
모델 오류의 책임:
  자동화된 의사결정: 의료, 법률, 금융 분야
  → 반드시 인간 검토 레이어 필요

출력 모니터링:
  - 유해 출력 자동 탐지 (Llama Guard 등)
  - 랜덤 샘플 사람 검토
  - 사용자 피드백 채널
  - 오류 보고 프로세스

레드라인 정의:
  절대 생성해서는 안 되는 콘텐츠 명확히 정의
  컨텍스트에 따른 예외 정책 문서화
  정기적 정책 리뷰
```

---

## 8. 연구 실험 설계

### Ablation Study
```
목적: 어떤 요소가 성능에 기여하는지 파악

좋은 ablation 설계:
  1. 베이스라인 고정 (control)
  2. 한 번에 하나씩 변경
  3. 충분한 실행 횟수 (seed 여러 개)
  4. 통계적 유의성 확인

예시: "새 attention 기법 효과 측정"
  실험 A: 기본 모델
  실험 B: 기본 + 새 attention
  실험 C: 기본 + 새 attention + 더 많은 데이터
  (실험 B-A = attention 효과, 실험 C-B = 데이터 효과)

흔한 실수:
  여러 변경을 동시에 → 어느 것이 효과인지 모름
  seed 1개만 → 통계적 노이즈
  다른 하이퍼파라미터 미조정
```

### 재현성 (Reproducibility)
```
공개 가능한 정보:
  - 정확한 모델 체크포인트 (HuggingFace Hub)
  - 학습 코드와 설정
  - 데이터 처리 코드
  - 평가 코드와 프롬프트
  - 하드웨어 환경

재현성 어려운 이유:
  - GPU 비결정론 (CUDA non-determinism)
  - 데이터 순서 (셔플링)
  - 라이브러리 버전 의존성
  - 클라우드 자원 노이즈

최선의 노력:
  - seed 고정 (torch.manual_seed, numpy.random.seed)
  - Dockerfile로 환경 고정
  - 여러 seed로 실험 → 분산 보고
  - 체크포인트 공개
```

### 효율적 실험 계획
```
HP 탐색 전략:
  Grid search: 모든 조합 (비용 큼)
  Random search: 무작위 (의외로 효과적)
  Bayesian optimization: 이전 결과 활용
  μP transfer: 작은 모델에서 찾은 HP 큰 모델에 적용

실험 추적:
  Weights & Biases: 가장 널리 사용
  MLflow: 오픈소스, 자체 호스팅
  TensorBoard: 기본 시각화

실험 우선순위:
  1. 빠른 실험 (작은 모델, 짧은 학습): 가설 검증
  2. 중간 규모: 스케일업 가능성 확인
  3. 전체 규모: 최종 검증
```

---

## Further Questions

**Q1. 새로운 LLM 프로젝트를 시작할 때 첫 2주의 로드맵은?**
```
Week 1:
  Day 1-2: 데이터 탐색, 태스크 명확화
  Day 3-4: 베이스라인 구축 (API + few-shot)
  Day 5: 평가 파이프라인 구축
  Weekend: 데이터 수집/정제 시작

Week 2:
  Day 1-2: 첫 파인튜닝 (작은 모델, 적은 데이터)
  Day 3: 평가, 오류 분석
  Day 4: 데이터 개선 또는 모델 변경
  Day 5: 스케일업 계획 수립

핵심: 평가 파이프라인을 먼저!
  좋은 평가 없이는 어떤 개선이 효과적인지 모름
```

**Q2. 모델이 기대만큼 안 나올 때 디버깅 순서는?**
```
1. 데이터 확인 (가장 많이 실패하는 원인):
   - 랜덤 100개 직접 읽어보기
   - Label 오류, 형식 불일치, 나쁜 예시 확인

2. 평가 확인:
   - 평가 자체가 잘못됐을 수 있음
   - 메트릭 계산 코드 버그 확인

3. 학습 과정 확인:
   - Loss curve 정상인지 (발산? 과적합?)
   - Gradient norm 안정적인지
   - LR이 적절한지

4. 모델 선택 재고:
   - 이 태스크에 더 적합한 모델이 있는가?
   - 파인튜닝 없이 강한 API 모델이 나을 수도

5. 태스크 재정의:
   - 태스크가 너무 어렵게 정의된 건 아닌가?
   - 사람도 잘 못하는 태스크인가?
```
